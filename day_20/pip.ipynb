{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Fetch the text from the URL\n",
    "response = requests.get('http://www.gutenberg.org/files/1112/1112.txt')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Extract text content\n",
    "    text = response.text\n",
    "    \n",
    "    # Clean the text: Remove punctuation and split into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    \n",
    "    # Create a Counter object to count word occurrences\n",
    "    word_counter = Counter(words)\n",
    "    \n",
    "    # Get the ten most frequent words\n",
    "    most_common_words = word_counter.most_common(10)\n",
    "    \n",
    "    print(\"The ten most frequent words in 'Romeo and Juliet':\")\n",
    "    print(most_common_words)\n",
    "else:\n",
    "    print(\"Failed to fetch the content. Status code:\", response.status_code)\n",
    "\n",
    "import requests # importing the request module\n",
    "\n",
    "url = 'https://www.w3.org/TR/PNG/iso_8859-1.txt' # text from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import statistics\n",
    "\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "# Fetch data from the Cat API\n",
    "response = requests.get(cats_api)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    cat_data = response.json()\n",
    "\n",
    "    # Extracting weight and lifespan data\n",
    "    weights = [cat['weight']['metric'].split()[0] for cat in cat_data if 'weight' in cat and 'metric' in cat['weight']]\n",
    "    lifespans = [cat['life_span'] for cat in cat_data if 'life_span' in cat]\n",
    "\n",
    "    # Converting weight strings to float values\n",
    "    weights = [float(weight) for weight in weights if weight.replace('.', '', 1).isdigit()]\n",
    "\n",
    "    # Calculating statistics for weight\n",
    "    min_weight = min(weights)\n",
    "    max_weight = max(weights)\n",
    "    mean_weight = statistics.mean(weights)\n",
    "    median_weight = statistics.median(weights)\n",
    "    std_dev_weight = statistics.stdev(weights)\n",
    "\n",
    "    # Converting lifespan strings to float values\n",
    "    lifespans = [float(lifespan.split()[0]) for lifespan in lifespans if lifespan.replace('.', '', 1).isdigit()]\n",
    "\n",
    "    # Calculating statistics for lifespan\n",
    "    min_lifespan = min(lifespans)\n",
    "    max_lifespan = max(lifespans)\n",
    "    mean_lifespan = statistics.mean(lifespans)\n",
    "    median_lifespan = statistics.median(lifespans)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fetch data from the REST Countries API\n",
    "api_url = 'https://restcountries.eu/rest/v2/all'\n",
    "response = requests.get(api_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # Task 1: Find the 10 largest countries\n",
    "    largest_countries = sorted(countries_data, key=lambda x: x['area'], reverse=True)[:10]\n",
    "    largest_countries_names = [country['name'] for country in largest_countries]\n",
    "    print(\"The 10 largest countries:\")\n",
    "    print(largest_countries_names)\n",
    "\n",
    "    # Task 2: Find the 10 most spoken languages\n",
    "    all_languages = [language for country in countries_data for language in country['languages']]\n",
    "    spoken_languages_count = {language['name']: all_languages.count(language['name']) for language in all_languages}\n",
    "    most_spoken_languages = sorted(spoken_languages_count.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"\\nThe 10 most spoken languages:\")\n",
    "    print(most_spoken_languages)\n",
    "\n",
    "    # Task 3: Find the total number of languages in the countries API\n",
    "    unique_languages = set(language['name'] for country in countries_data for language in country['languages'])\n",
    "    total_languages_count = len(unique_languages)\n",
    "    print(\"\\nThe total number of languages in the countries API:\")\n",
    "    print(total_languages_count)\n",
    "\n",
    "else:\n",
    "    print(\"Failed to fetch data. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    uci_data = response.text\n",
    "    # Process the retrieved content as needed\n",
    "    print(uci_data[:500])  # Display the first 500 characters of the fetched content\n",
    "else:\n",
    "    print(\"Failed to fetch data. Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
