{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "\n",
    "response = requests.get(url)\n",
    "# lets check the status\n",
    "status = response.status_code\n",
    "print(status) # 404 means the fetching was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped successfully and saved to bu_data.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def scrape_bu_data(url, output_file):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Example: Extracting data from paragraphs with class \"bu-fact\"\n",
    "        bu_facts = soup.find_all('p', class_='bu-fact')\n",
    "        facts_data = [fact.text.strip() for fact in bu_facts]\n",
    "\n",
    "        # Save the scraped data as JSON\n",
    "        with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump({'bu_facts': facts_data}, json_file, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"Data scraped successfully and saved to {output_file}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "url = 'http://www.bu.edu/president/boston-university-facts-stats/'\n",
    "output_file = 'bu_data.json'\n",
    "scrape_bu_data(url, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped successfully and saved to presidents_data.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def scrape_presidents_table(url, output_file):\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Find the table containing the list of presidents\n",
    "        presidents_table = None\n",
    "        for table in soup.find_all('table', {'class': 'wikitable'}):\n",
    "            if 'Presidency' in str(table):  # Assuming the table contains the word 'Presidency'\n",
    "                presidents_table = table\n",
    "                break\n",
    "\n",
    "        if presidents_table:\n",
    "            # Extract data from the table\n",
    "            presidents_data = []\n",
    "            rows = presidents_table.find_all('tr')\n",
    "            for row in rows[1:]:  # Skip the header row\n",
    "                columns = row.find_all(['th', 'td'])\n",
    "                president_info = [column.text.strip() for column in columns]\n",
    "                presidents_data.append(president_info)\n",
    "\n",
    "            # Save the scraped data as JSON\n",
    "            with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "                json.dump({'presidents_data': presidents_data}, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(f\"Data scraped successfully and saved to {output_file}\")\n",
    "        else:\n",
    "            print(\"Presidents table not found on the page.\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States'\n",
    "output_file = 'presidents_data.json'\n",
    "scrape_presidents_table(url, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
